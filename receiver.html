<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <script src="//www.gstatic.com/cast/sdk/libs/caf_receiver/v3/cast_receiver_framework.js"></script>
    <style>
        html, body {
            margin: 0; padding: 0;
            width: 100%; height: 100%;
            background: #000; overflow: hidden;
        }
        video {
            width: 100%; height: 100%;
            object-fit: contain;
            background: #000;
        }
        #welcome-img {
            display: none;
            position: fixed; top: 0; left: 0;
            width: 100%; height: 100%;
            object-fit: contain;
            background: #000;
            z-index: 5;
        }
        #status {
            position: fixed; top: 50%; left: 50%;
            transform: translate(-50%, -50%);
            color: #fff; font: 24px -apple-system, sans-serif;
            text-align: center;
            display: none;
            z-index: 10;
            pointer-events: none;
        }
    </style>
</head>
<body>
    <div id="status">Waiting for stream…</div>
    <img id="welcome-img" />
    <video id="v" autoplay playsinline></video>
    <script>
    'use strict';

    const NS  = 'urn:x-cast:com.screenmirror.stream';
    const TAG = '[SMReceiver]';

    const statusEl   = document.getElementById('status');
    const video      = document.getElementById('v');
    const welcomeImg = document.getElementById('welcome-img');

    const ctx = cast.framework.CastReceiverContext.getInstance();
    const pm  = ctx.getPlayerManager();
    let senderBusId = null;

    function report(msg) {
        console.log(TAG, msg);
        if (senderBusId) {
            try { ctx.sendCustomMessage(NS, senderBusId, {type:'DIAG', msg:msg}); } catch(_){}
        }
    }
    function showStatus(text) { statusEl.textContent = text; statusEl.style.display = 'block'; }
    function hideStatus() { statusEl.style.display = 'none'; }

    // ═══════════════════════════════════════════════════════════════
    // Cast Message Handling
    // ═══════════════════════════════════════════════════════════════

    ctx.addCustomMessageListener(NS, event => {
        senderBusId = event.senderId;
        const d = event.data;
        if (d.type === 'WEBRTC_OFFER') {
            report('WEBRTC_OFFER received');
            video.muted = (d.soundEnabled === false);
            startWebRTC(d.sdp);
        }
        else if (d.type === 'WEBRTC_ICE') {
            if (pc && d.candidate) {
                pc.addIceCandidate({ candidate: d.candidate, sdpMid: d.sdpMid || '', sdpMLineIndex: d.sdpMLineIndex || 0 })
                  .catch(e => report('addIceCandidate error: ' + e.message));
            }
        }
        else if (d.type === 'STOP_STREAM')  { stopStream(); }
        else if (d.type === 'SHOW_WELCOME') { report('SHOW_WELCOME: ' + d.imageUrl); showWelcome(d.imageUrl); }
        else if (d.type === 'SET_SOUND')    { report('SET_SOUND: ' + d.enabled); video.muted = !d.enabled; }
    });

    pm.setMessageInterceptor(cast.framework.messages.MessageType.LOAD, req => {
        return null;
    });

    const opts = new cast.framework.CastReceiverOptions();
    opts.disableIdleTimeout = true;
    opts.statusText = '';
    opts.customNamespaces = {};
    opts.customNamespaces[NS] = cast.framework.system.MessageType.JSON;
    ctx.start(opts);
    report('Receiver v7 — WebRTC DataChannel (UDP/SCTP/DTLS)');

    // ═══════════════════════════════════════════════════════════════
    // State
    // ═══════════════════════════════════════════════════════════════

    let pc = null;           // RTCPeerConnection
    let dc = null;           // RTCDataChannel
    let mediaSource = null, sourceBuffer = null;
    let queue = [], appending = false, initReceived = false;
    let lastInitSeg = null;
    let hasPlayed = false;
    let diagTimer = null, statusTimer = null, liveTimer = null;
    let streamStartTime = 0;
    let totalBytes = 0, fragments = 0;
    let seekCount = 0, waitCount = 0;
    let lastDropped = 0, lastTotal = 0;
    let errorReinitCount = 0;
    let lastObjectURL = null;
    let playAttemptPending = false;
    let lastSeekTime = 0;
    let playRetryCount = 0;

    // ═══════════════════════════════════════════════════════════════
    // Welcome Image
    // ═══════════════════════════════════════════════════════════════

    function showWelcome(imageUrl) {
        stopStream();
        welcomeImg.src = imageUrl;
        welcomeImg.style.display = 'block';
        video.style.display = 'none';
        hideStatus();
    }

    // ═══════════════════════════════════════════════════════════════
    // WebRTC DataChannel Transport (UDP/SCTP/DTLS)
    // ═══════════════════════════════════════════════════════════════

    function startWebRTC(offerSDP) {
        welcomeImg.style.display = 'none';
        video.style.display = 'block';
        showStatus('Connecting…');
        stopStream();

        errorReinitCount = 0;
        streamStartTime = Date.now();
        report('Starting WebRTC peer connection');

        // LAN only — no STUN/TURN servers needed
        const config = {
            iceServers: [],
            bundlePolicy: 'max-bundle',
            rtcpMuxPolicy: 'require',
            sdpSemantics: 'unified-plan'
        };

        try {
            pc = new RTCPeerConnection(config);
        } catch(e) {
            report('RTCPeerConnection failed: ' + e.message);
            sendUnsupported();
            return;
        }

        // Incoming DataChannel from the phone (offerer creates it)
        pc.ondatachannel = (event) => {
            dc = event.channel;
            dc.binaryType = 'arraybuffer';
            report('DataChannel opened: ' + dc.label + ' ordered=' + dc.ordered);

            dc.onmessage = (evt) => {
                const data = new Uint8Array(evt.data);
                totalBytes += data.length;
                fragments++;

                if (!initReceived) {
                    initReceived = true;
                    lastInitSeg = data;
                    report('Init segment: ' + data.length + ' bytes');
                    createMSE(data);
                    return;
                }

                // Detect re-init (resolution change) — ftyp box
                if (data.length > 7 && data[4]===0x66 && data[5]===0x74 && data[6]===0x79 && data[7]===0x70) {
                    lastInitSeg = data;
                    report('Re-init: ' + data.length + ' bytes');
                    reinitMSE();
                    return;
                }

                enqueue(data);
            };

            dc.onclose = () => {
                report('DataChannel closed');
                showStatus('Stream ended');
            };

            dc.onerror = (e) => {
                report('DataChannel error: ' + (e.error ? e.error.message : '?'));
            };
        };

        // Send local ICE candidates to the phone via Cast namespace
        pc.onicecandidate = (event) => {
            if (event.candidate && senderBusId) {
                try {
                    ctx.sendCustomMessage(NS, senderBusId, {
                        type: 'WEBRTC_ICE',
                        candidate: event.candidate.candidate,
                        sdpMid: event.candidate.sdpMid,
                        sdpMLineIndex: event.candidate.sdpMLineIndex
                    });
                } catch(_) {}
            }
        };

        pc.oniceconnectionstatechange = () => {
            const st = pc.iceConnectionState;
            report('ICE state: ' + st);
            if (st === 'connected' || st === 'completed') {
                showStatus('Buffering…');
            } else if (st === 'failed') {
                report('ICE connection failed');
                showStatus('Connection failed');
            } else if (st === 'disconnected') {
                report('ICE disconnected — waiting for recovery');
            }
        };

        // Set remote offer → create answer → send back via Cast
        pc.setRemoteDescription({ type: 'offer', sdp: offerSDP })
          .then(() => pc.createAnswer())
          .then(answer => {
              // Increase SCTP max-message-size for large keyframe fragments
              let sdp = answer.sdp;
              if (sdp.indexOf('a=max-message-size:') !== -1) {
                  sdp = sdp.replace(/a=max-message-size:\d+/, 'a=max-message-size:262144');
              }
              return pc.setLocalDescription({ type: 'answer', sdp: sdp });
          })
          .then(() => {
              report('WebRTC answer ready, sending to phone');
              try {
                  ctx.sendCustomMessage(NS, senderBusId, {
                      type: 'WEBRTC_ANSWER',
                      sdp: pc.localDescription.sdp
                  });
              } catch(e) {
                  report('Failed to send WEBRTC_ANSWER: ' + e.message);
              }
          })
          .catch(e => {
              report('WebRTC setup failed: ' + e.message);
              sendUnsupported();
          });

        startDiag();
        startLiveLoop();
    }

    function sendUnsupported() {
        if (senderBusId) {
            try { ctx.sendCustomMessage(NS, senderBusId, { type: 'WEBRTC_UNSUPPORTED' }); } catch(_) {}
        }
    }

    // ═══════════════════════════════════════════════════════════════
    // Stream Control
    // ═══════════════════════════════════════════════════════════════

    function revokeURL() {
        if (lastObjectURL) {
            URL.revokeObjectURL(lastObjectURL);
            lastObjectURL = null;
        }
    }

    function stopStream() {
        if (dc) { try { dc.close(); } catch(_) {} dc = null; }
        if (pc) { try { pc.close(); } catch(_) {} pc = null; }
        if (diagTimer) { clearInterval(diagTimer); diagTimer = null; }
        if (statusTimer) { clearInterval(statusTimer); statusTimer = null; }
        if (liveTimer) { clearInterval(liveTimer); liveTimer = null; }
        if (mediaSource && mediaSource.readyState === 'open') {
            try { mediaSource.endOfStream(); } catch(_){}
        }
        revokeURL();
        mediaSource = null;
        sourceBuffer = null;
        queue = [];
        appending = false;
        initReceived = false;
        hasPlayed = false;
        playAttemptPending = false;
        totalBytes = 0;
        fragments = 0;
        seekCount = 0;
        waitCount = 0;
    }

    // ═══════════════════════════════════════════════════════════════
    // MSE Pipeline (SourceBuffer playback)
    // ═══════════════════════════════════════════════════════════════

    function createMSE(initSeg) {
        if (mediaSource && mediaSource.readyState === 'open') {
            try { mediaSource.endOfStream(); } catch(_){}
        }
        mediaSource = null;
        sourceBuffer = null;
        queue = [];
        appending = false;

        mediaSource = new MediaSource();
        mediaSource.addEventListener('sourceopen', () => {
            report('MSE sourceopen');

            const codec = detectCodec(initSeg) || 'avc1.640029,mp4a.40.2';
            report('Codec: ' + codec);

            try {
                sourceBuffer = mediaSource.addSourceBuffer('video/mp4; codecs="' + codec + '"');
            } catch(e) {
                report('addSourceBuffer failed: ' + e.message + ', trying fallback');
                try {
                    sourceBuffer = mediaSource.addSourceBuffer('video/mp4; codecs="avc1.42E01E,mp4a.40.2"');
                } catch(e2) {
                    report('All codec attempts failed: ' + e2.message);
                    return;
                }
            }

            sourceBuffer.mode = 'sequence';
            sourceBuffer.addEventListener('updateend', onUpdateEnd);
            sourceBuffer.addEventListener('error', () => {
                report('SourceBuffer error');
                queue = [];
                appending = false;
            });

            queue.unshift(initSeg);
            drainQueue();

            statusTimer = setInterval(() => {
                attemptPlay();
                if (hasPlayed && statusTimer) {
                    clearInterval(statusTimer);
                    statusTimer = null;
                }
            }, 150);
        });

        mediaSource.addEventListener('sourceended', () => report('MSE sourceended'));
        mediaSource.addEventListener('sourceclose', () => report('MSE sourceclose'));

        revokeURL();
        lastObjectURL = URL.createObjectURL(mediaSource);
        video.src = lastObjectURL;
    }

    function reinitMSE() {
        report('reinitMSE');
        if (dc && dc.readyState === 'open') {
            try { dc.send('FORCE_KEYFRAME'); } catch(_) {}
        }
        if (statusTimer) { clearInterval(statusTimer); statusTimer = null; }
        if (mediaSource && mediaSource.readyState === 'open') {
            try { mediaSource.endOfStream(); } catch(_){}
        }
        revokeURL();
        // Fully reset video element to clear stale decoder pipeline
        video.removeAttribute('src');
        video.load();
        mediaSource = null;
        sourceBuffer = null;
        queue = [];
        appending = false;
        hasPlayed = false;
        playAttemptPending = false;
        errorReinitCount = 0;
        if (lastInitSeg) createMSE(lastInitSeg);
    }

    function enqueue(data) {
        // Drop fragments while MSE is initializing or in bad state
        if (!sourceBuffer || !mediaSource || mediaSource.readyState !== 'open') return;
        if (queue.length >= 12) {
            const drop = queue.length - 4;
            queue.splice(0, drop);
            report('Dropped ' + drop + ' queued fragments (backpressure)');
        }
        queue.push(data);
        drainQueue();
    }

    function drainQueue() {
        if (appending || !sourceBuffer || queue.length === 0) return;
        if (sourceBuffer.updating) return;
        if (!mediaSource || mediaSource.readyState !== 'open') { queue = []; return; }

        appending = true;
        const chunk = queue.shift();
        try {
            sourceBuffer.appendBuffer(chunk);
        } catch(e) {
            appending = false;
            report('appendBuffer error: ' + e.name);
            if (e.name === 'QuotaExceededError') {
                trimBuffer();
            } else if (e.name === 'InvalidStateError') {
                queue = [];  // MSE in bad state — stop trying, wait for reinit
            }
        }
    }

    function onUpdateEnd() {
        appending = false;
        if (!hasPlayed && sourceBuffer && sourceBuffer.buffered.length > 0) {
            attemptPlay();
        }
        drainQueue();
    }

    function attemptPlay() {
        if (hasPlayed || playAttemptPending) return;
        if (!sourceBuffer || sourceBuffer.buffered.length === 0) return;

        // Find the last buffered range with at least 0.3s of data
        const nRanges = sourceBuffer.buffered.length;
        let targetStart = -1;
        for (let i = nRanges - 1; i >= 0; i--) {
            const rs = sourceBuffer.buffered.start(i);
            const re = sourceBuffer.buffered.end(i);
            if (re - rs >= 0.3) { targetStart = rs; break; }
        }
        if (targetStart < 0) return;

        playAttemptPending = true;
        playRetryCount++;
        video.currentTime = targetStart + 0.05;
        report('attemptPlay #' + playRetryCount + ' ct→' + video.currentTime.toFixed(2));

        // Timeout: if play doesn't succeed in 2s, allow retry
        const playTimeout = setTimeout(() => {
            if (!hasPlayed) {
                playAttemptPending = false;
                report('play() timeout — will retry');
            }
        }, 2000);

        video.play().then(() => {
            clearTimeout(playTimeout);
            hasPlayed = true;
            playAttemptPending = false;
            hideStatus();
            report('PLAYING ct=' + video.currentTime.toFixed(3));
        }).catch(e => {
            clearTimeout(playTimeout);
            report('play() error: ' + (e ? e.name : '?'));
            if (!video.muted) {
                video.muted = true;
                video.play().then(() => {
                    hasPlayed = true;
                    playAttemptPending = false;
                    hideStatus();
                    video.muted = false;
                    report('PLAYING (muted workaround)');
                }).catch(() => { playAttemptPending = false; });
            } else {
                playAttemptPending = false;
            }
        });
    }

    function trimBuffer() {
        if (!sourceBuffer || sourceBuffer.buffered.length === 0 || sourceBuffer.updating) return;
        try {
            const start = sourceBuffer.buffered.start(0);
            const keep = Math.max(start, video.currentTime - 1.0);
            if (keep > start + 0.5) {
                sourceBuffer.remove(start, keep);
            }
        } catch(_) {}
    }

    // ═══════════════════════════════════════════════════════════════
    // Video Event Handlers
    // ═══════════════════════════════════════════════════════════════

    video.addEventListener('waiting', () => {
        if (!hasPlayed || !sourceBuffer || sourceBuffer.buffered.length === 0) return;
        waitCount++;
        const now = Date.now();
        const ct = video.currentTime;
        const nRanges = sourceBuffer.buffered.length;

        // Check if playhead is inside any buffered range
        let inRange = false;
        for (let i = 0; i < nRanges; i++) {
            if (ct >= sourceBuffer.buffered.start(i) - 0.05 && ct <= sourceBuffer.buffered.end(i)) {
                inRange = true;
                break;
            }
        }

        if (!inRange && now - lastSeekTime >= 500) {
            // Playhead is in a gap — jump to the next available range
            for (let i = 0; i < nRanges; i++) {
                if (sourceBuffer.buffered.start(i) > ct) {
                    video.currentTime = sourceBuffer.buffered.start(i) + 0.05;
                    lastSeekTime = now;
                    seekCount++;
                    report('waiting → gap-skip ' + ct.toFixed(2) + '→' + sourceBuffer.buffered.start(i).toFixed(2));
                    return;
                }
            }
        }

        // Within a range — decoder needs time. Do NOT seek (causes cascade).
        // Slow playback rate to let buffer grow.
        video.playbackRate = 0.85;
    });

    video.addEventListener('stalled', () => {
        if (!sourceBuffer || sourceBuffer.buffered.length === 0) return;
        const ct = video.currentTime;
        const nRanges = sourceBuffer.buffered.length;
        const now = Date.now();

        let inRange = false;
        for (let i = 0; i < nRanges; i++) {
            if (ct >= sourceBuffer.buffered.start(i) - 0.05 && ct <= sourceBuffer.buffered.end(i)) {
                inRange = true;
                break;
            }
        }

        if (!inRange && now - lastSeekTime >= 500) {
            for (let i = 0; i < nRanges; i++) {
                if (sourceBuffer.buffered.start(i) > ct) {
                    video.currentTime = sourceBuffer.buffered.start(i) + 0.05;
                    lastSeekTime = now;
                    seekCount++;
                    report('stalled → gap-skip to ' + sourceBuffer.buffered.start(i).toFixed(2));
                    return;
                }
            }
        }

        video.playbackRate = 0.85;
    });

    video.addEventListener('canplay', () => {
        report('canplay rs=' + video.readyState);
        if (!hasPlayed) attemptPlay();
    });

    video.addEventListener('playing', () => {
        hideStatus();
        if (!hasPlayed) { hasPlayed = true; playAttemptPending = false; }
    });

    video.addEventListener('error', () => {
        const err = video.error;
        report('video error: code=' + (err ? err.code : '?') + ' reinits=' + errorReinitCount);
        errorReinitCount++;
        if (errorReinitCount > 5) {
            report('Too many error reinits — stopping');
            showStatus('Playback error');
            return;
        }
        if (lastInitSeg) {
            setTimeout(() => reinitMSE(), 300 * errorReinitCount);
        }
    });

    // ═══════════════════════════════════════════════════════════════
    // Live Loop & Diagnostics
    // ═══════════════════════════════════════════════════════════════

    function startLiveLoop() {
        if (liveTimer) clearInterval(liveTimer);
        liveTimer = setInterval(() => {
            if (!sourceBuffer || sourceBuffer.buffered.length === 0) return;

            // Play recovery: if video hasn't started after 3s, force retry
            if (!hasPlayed && sourceBuffer.buffered.length > 0 && streamStartTime > 0 && Date.now() - streamStartTime > 3000) {
                if (!playAttemptPending && playRetryCount < 15) {
                    report('Play recovery #' + (playRetryCount + 1));
                    attemptPlay();
                }
            }

            if (video.paused && hasPlayed) video.play().catch(() => {});

            const ct = video.currentTime;
            const edge = sourceBuffer.buffered.end(sourceBuffer.buffered.length - 1);
            const drift = edge - ct;

            // ── Playback rate compensation ──
            // Keep buffer margin at ~0.3-0.5s ahead of playhead.
            // Instead of hard-seeking (visible stutter), gently adjust
            // playback speed to let buffer grow or shrink naturally.
            if (hasPlayed && !video.paused) {
                if (drift < 0.15) {
                    // Dangerously thin — slow down to let buffer grow
                    video.playbackRate = 0.92;
                } else if (drift < 0.3) {
                    // Thin buffer — ease off slightly
                    video.playbackRate = 0.97;
                } else if (drift > 1.0) {
                    // Too far behind live edge — catch up
                    video.playbackRate = 1.06;
                } else if (drift > 0.6) {
                    // Slightly behind — gentle catch-up
                    video.playbackRate = 1.02;
                } else {
                    // Sweet spot (0.3–0.6s) — normal speed
                    video.playbackRate = 1.0;
                }
            }

            // Hard seek only when severely behind (>1.5s)
            if (drift > 1.5 && hasPlayed) {
                video.currentTime = edge - 0.35;
                seekCount++;
            }

            if (!sourceBuffer.updating && hasPlayed) {
                const bufStart = sourceBuffer.buffered.start(0);
                const removeEnd = ct - 3.0;
                if (removeEnd > bufStart + 0.5) {
                    try { sourceBuffer.remove(bufStart, removeEnd); } catch(_) {}
                }
            }

            // Proactive gap-skip: if buffer has 2+ ranges and playhead is
            // approaching a gap, jump past it BEFORE waiting event fires.
            const nRanges = sourceBuffer.buffered.length;
            if (hasPlayed && nRanges >= 2 && Date.now() - lastSeekTime >= 500) {
                // Find the gap the playhead is about to hit
                for (let i = 0; i < nRanges - 1; i++) {
                    const rangeEnd = sourceBuffer.buffered.end(i);
                    const nextStart = sourceBuffer.buffered.start(i + 1);
                    // If playhead is within 0.15s of the gap boundary, skip it
                    if (ct >= rangeEnd - 0.15 && ct < nextStart) {
                        video.currentTime = nextStart + 0.05;
                        lastSeekTime = Date.now();
                        seekCount++;
                        report('liveLoop → gap-skip ' + rangeEnd.toFixed(2) + '→' + nextStart.toFixed(2));
                        break;
                    }
                }
            }

            // If buffer is severely fragmented (4+ ranges), full reinit
            if (hasPlayed && nRanges >= 4) {
                report('Fragmented buffer (' + nRanges + ' ranges) — reinit');
                reinitMSE();
            }

            if (hasPlayed && !video.paused && drift < 0.5) {
                errorReinitCount = 0;
            }
        }, 200);
    }

    function startDiag() {
        if (diagTimer) clearInterval(diagTimer);
        diagTimer = setInterval(() => {
            const elapsed = ((Date.now() - streamStartTime) / 1000).toFixed(1);
            const ct = video.currentTime.toFixed(2);
            const paused = video.paused ? 'PAUSED' : 'playing';
            const muted = video.muted ? 'muted' : 'unmuted';

            let bufInfo = 'none';
            if (sourceBuffer && sourceBuffer.buffered.length > 0) {
                const bs = sourceBuffer.buffered.start(0).toFixed(2);
                const be = sourceBuffer.buffered.end(sourceBuffer.buffered.length - 1).toFixed(2);
                bufInfo = bs + '-' + be + '(' + sourceBuffer.buffered.length + ')';
            }

            let dropInfo = '';
            if (video.getVideoPlaybackQuality) {
                const q = video.getVideoPlaybackQuality();
                const nd = q.droppedVideoFrames - lastDropped;
                const nt = q.totalVideoFrames - lastTotal;
                dropInfo = ' drop=' + q.droppedVideoFrames + '/' + q.totalVideoFrames
                    + '(+' + nd + '/' + nt + ')';
                lastDropped = q.droppedVideoFrames;
                lastTotal = q.totalVideoFrames;
            }

            const kbps = streamStartTime > 0
                ? ((totalBytes * 8) / ((Date.now() - streamStartTime) / 1000) / 1000).toFixed(0)
                : '0';

            const iceState = pc ? pc.iceConnectionState : 'none';

            report('DIAG t=' + elapsed + 's ct=' + ct + ' ' + paused + ' ' + muted
                + ' buf=[' + bufInfo + '] q=' + queue.length
                + ' frags=' + fragments + ' ' + kbps + 'kbps'
                + ' seeks=' + seekCount + ' waits=' + waitCount + dropInfo
                + ' ice=' + iceState);
        }, 5000);
    }

    function detectCodec(d) {
        let videoCodec = null, hasAudio = false;
        for (let i = 0; i < d.length - 4; i++) {
            if (!videoCodec && i + 7 < d.length &&
                d[i]===0x61 && d[i+1]===0x76 && d[i+2]===0x63 && d[i+3]===0x43) {
                if (d[i+4] === 1) {
                    const h = n => n.toString(16).padStart(2, '0');
                    videoCodec = 'avc1.' + h(d[i+5]) + h(d[i+6]) + h(d[i+7]);
                }
            }
            if (d[i]===0x6D && d[i+1]===0x70 && d[i+2]===0x34 && d[i+3]===0x61) hasAudio = true;
            if (d[i]===0x65 && d[i+1]===0x73 && d[i+2]===0x64 && d[i+3]===0x73) hasAudio = true;
        }
        if (videoCodec && (hasAudio || d.length > 800)) return videoCodec + ',mp4a.40.2';
        return videoCodec;
    }
    </script>
</body>
</html>
