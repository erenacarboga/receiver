<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <script src="//www.gstatic.com/cast/sdk/libs/caf_receiver/v3/cast_receiver_framework.js"></script>
    <style>
        html, body {
            margin: 0; padding: 0;
            width: 100%; height: 100%;
            background: #000; overflow: hidden;
        }
        video {
            width: 100%; height: 100%;
            object-fit: contain;
            background: #000;
        }
        #welcome-img {
            display: none;
            position: fixed; top: 0; left: 0;
            width: 100%; height: 100%;
            object-fit: contain;
            background: #000;
            z-index: 5;
        }
        #status {
            position: fixed; top: 50%; left: 50%;
            transform: translate(-50%, -50%);
            color: #fff; font: 24px -apple-system, sans-serif;
            text-align: center; opacity: 0;
            transition: opacity 0.4s;
            z-index: 10;
            pointer-events: none;
        }
        #status.visible { opacity: 0.8; }
    </style>
</head>
<body>
    <div id="status">Waiting for stream…</div>
    <img id="welcome-img" />
    <video id="v" autoplay muted playsinline></video>
    <script>
    'use strict';

    const NS  = 'urn:x-cast:com.screenmirror.stream';
    const TAG = '[SMReceiver]';

    const statusEl   = document.getElementById('status');
    const video      = document.getElementById('v');
    const welcomeImg = document.getElementById('welcome-img');

    const ctx = cast.framework.CastReceiverContext.getInstance();
    const pm  = ctx.getPlayerManager();
    let senderBusId = null;

    function report(msg) {
        console.log(TAG, msg);
        if (senderBusId) {
            try { ctx.sendCustomMessage(NS, senderBusId, {type:'DIAG', msg:msg}); } catch(_){}
        }
    }

    function showStatus(text) {
        statusEl.textContent = text;
        statusEl.classList.add('visible');
    }
    function hideStatus() {
        statusEl.classList.remove('visible');
    }

    ctx.addCustomMessageListener(NS, event => {
        senderBusId = event.senderId;
        const d = event.data;
        if (d.type === 'START_STREAM')       { report('START_STREAM: ' + d.wsUrl);     startStream(d.wsUrl); }
        else if (d.type === 'STOP_STREAM')   { stopStream(); }
        else if (d.type === 'SHOW_WELCOME')  { report('SHOW_WELCOME: ' + d.imageUrl); showWelcome(d.imageUrl); }
    });

    pm.setMessageInterceptor(cast.framework.messages.MessageType.LOAD, req => {
        try {
            const url = new URL(req.media.contentId);
            startStream('ws://' + url.hostname + ':8082/stream');
        } catch(e) { report('LOAD error: ' + e.message); }
        return null;
    });

    const opts = new cast.framework.CastReceiverOptions();
    opts.disableIdleTimeout = true;
    opts.statusText = '';
    opts.customNamespaces = {};
    opts.customNamespaces[NS] = cast.framework.system.MessageType.JSON;
    ctx.start(opts);
    report('Receiver v4 started');

    let ws = null;
    let mediaSource = null, sourceBuffer = null;
    let queue = [], appending = false, initReceived = false;
    let lastInitSeg = null;
    let hasPlayed = false;
    let statusTimer = null;

    let audioSourceBuffer = null;
    let audioQueue = [], audioAppending = false, audioInitReceived = false;
    let lastAudioInitSeg = null;

    const LATENCY_CHECK_MS    = 200;
    const MAX_DRIFT_SEC       = 0.25;
    const TRIM_INTERVAL_MS    = 2000;
    const TRIM_KEEP_BEHIND    = 1.0;
    const STALL_TIMEOUT_MS    = 5000;
    const REINIT_COOLDOWN_MS  = 3000;
    const QUEUE_MAX           = 20;
    const AUDIO_QUEUE_MAX     = 40;

    let lastProgressTime = 0, lastProgressCT = -1;
    let lastTrimTime = 0, lastReinitTime = 0;
    let latencyTimer = null;

    function showWelcome(imageUrl) {
        stopStream();
        welcomeImg.src = imageUrl;
        welcomeImg.style.display = 'block';
        video.style.display = 'none';
        hideStatus();
    }

    function startStream(wsUrl) {
        welcomeImg.style.display = 'none';
        video.style.display = 'block';
        showStatus('Connecting…');
        stopStream();

        ws = new WebSocket(wsUrl);
        ws.binaryType = 'arraybuffer';

        ws.onopen = () => {
            report('WebSocket connected');
            showStatus('Buffering…');
        };

        ws.onmessage = (evt) => {
            const raw = new Uint8Array(evt.data);
            if (raw.length === 0) return;

            if (raw[0] === 0x01) {
                const audioData = new Uint8Array(evt.data, 1);
                handleAudioData(audioData);
                return;
            }

            handleVideoData(raw);
        };

        ws.onerror = () => {
            report('WS error');
            showStatus('Connection error');
        };

        ws.onclose = () => {
            report('WS closed');
            const url = wsUrl;
            setTimeout(() => {
                if (!ws || ws.readyState === WebSocket.CLOSED) {
                    initReceived = false;
                    audioInitReceived = false;
                    startStream(url);
                }
            }, 300);
        };
    }

    function handleVideoData(data) {
        if (!initReceived) {
            initReceived = true;
            lastInitSeg = data;
            report('Init segment: ' + data.length + ' bytes');
            createMSE(data);
            return;
        }

        if (data.length > 7 && data[4]===0x66 && data[5]===0x74 && data[6]===0x79 && data[7]===0x70) {
            lastInitSeg = data;
            report('Re-init (resolution change): ' + data.length + ' bytes');
            reinitMSE();
            return;
        }
        enqueue(data);
    }

    function handleAudioData(data) {
        if (!mediaSource || mediaSource.readyState !== 'open') {
            return;
        }

        if (data.length > 7 && data[4]===0x66 && data[5]===0x74 && data[6]===0x79 && data[7]===0x70) {
            lastAudioInitSeg = data;
            if (!audioInitReceived) {
                audioInitReceived = true;
                report('Audio init segment: ' + data.length + ' bytes');
                createAudioSourceBuffer(data);
            } else {
                report('Audio re-init: ' + data.length + ' bytes');
                recreateAudioSourceBuffer();
            }
            return;
        }

        if (!audioSourceBuffer) return;
        audioEnqueue(data);
    }

    function createAudioSourceBuffer(initSeg) {
        if (!mediaSource || mediaSource.readyState !== 'open') return;
        try {
            audioSourceBuffer = mediaSource.addSourceBuffer('audio/mp4; codecs="mp4a.40.2"');
            audioSourceBuffer.mode = 'sequence';
            audioSourceBuffer.addEventListener('updateend', onAudioUpdateEnd);
            audioSourceBuffer.addEventListener('error', () => {
                report('Audio SourceBuffer error');
            });
            audioQueue.unshift(initSeg);
            drainAudioQueue();
            report('Audio SourceBuffer created');

            video.muted = false;
            report('Video unmuted (audio track available)');
        } catch(e) {
            report('Audio addSourceBuffer failed: ' + e.message);
            audioSourceBuffer = null;
        }
    }

    function recreateAudioSourceBuffer() {
        if (lastAudioInitSeg && audioSourceBuffer) {
            audioQueue = [];
            audioAppending = false;
            audioQueue.push(lastAudioInitSeg);
            drainAudioQueue();
        }
    }

    function audioEnqueue(data) {
        if (audioQueue.length >= AUDIO_QUEUE_MAX) {
            const drop = audioQueue.length - Math.floor(AUDIO_QUEUE_MAX / 2);
            audioQueue.splice(0, drop);
        }
        audioQueue.push(data);
        drainAudioQueue();
    }

    function drainAudioQueue() {
        if (audioAppending || !audioSourceBuffer || audioQueue.length === 0) return;
        if (audioSourceBuffer.updating) return;
        audioAppending = true;
        const chunk = audioQueue.shift();
        try {
            audioSourceBuffer.appendBuffer(chunk);
        } catch(e) {
            audioAppending = false;
            report('Audio appendBuffer error: ' + e.name);
        }
    }

    function onAudioUpdateEnd() {
        audioAppending = false;
        drainAudioQueue();
    }

    function stopStream() {
        if (latencyTimer) { clearInterval(latencyTimer); latencyTimer = null; }
        if (statusTimer)  { clearInterval(statusTimer);  statusTimer = null; }
        if (ws) { ws.onclose = null; ws.onerror = null; ws.close(); ws = null; }

        if (mediaSource && mediaSource.readyState === 'open') {
            try { mediaSource.endOfStream(); } catch(_){}
        }
        mediaSource = null;
        sourceBuffer = null;
        audioSourceBuffer = null;
        queue = [];
        audioQueue = [];
        appending = false;
        audioAppending = false;
        initReceived = false;
        audioInitReceived = false;
        hasPlayed = false;
        lastProgressCT = -1;
        lastProgressTime = 0;
    }

    function createMSE(initSeg) {
        mediaSource = new MediaSource();

        mediaSource.addEventListener('sourceopen', () => {
            report('MSE sourceopen');
            const codec = detectCodec(initSeg) || 'avc1.640029';
            report('Codec: ' + codec);

            try {
                sourceBuffer = mediaSource.addSourceBuffer('video/mp4; codecs="' + codec + '"');
            } catch(e) {
                report('addSourceBuffer failed: ' + e.message + ' — trying baseline');
                try {
                    sourceBuffer = mediaSource.addSourceBuffer('video/mp4; codecs="avc1.42E01E"');
                } catch(e2) {
                    report('Baseline also failed: ' + e2.message);
                    return;
                }
            }

            sourceBuffer.mode = 'sequence';
            sourceBuffer.addEventListener('updateend', onUpdateEnd);
            sourceBuffer.addEventListener('error', () => {
                report('SourceBuffer error');
                reinitMSE();
            });

            queue.unshift(initSeg);
            drainQueue();

            startLatencyController();

            statusTimer = setInterval(() => {
                attemptPlay();
                if (hasPlayed && statusTimer) {
                    clearInterval(statusTimer);
                    statusTimer = null;
                }
            }, 100);

            if (lastAudioInitSeg) {
                audioInitReceived = true;
                createAudioSourceBuffer(lastAudioInitSeg);
            }
        });

        mediaSource.addEventListener('sourceended', () => report('MSE sourceended'));
        mediaSource.addEventListener('sourceclose', () => report('MSE sourceclose'));

        video.src = URL.createObjectURL(mediaSource);
        report('video.src set, waiting for sourceopen…');
    }

    function reinitMSE() {
        const now = Date.now();
        if (now - lastReinitTime < REINIT_COOLDOWN_MS) return;
        lastReinitTime = now;

        report('reinitMSE');

        if (ws && ws.readyState === WebSocket.OPEN) {
            ws.send('FORCE_KEYFRAME');
        }

        if (latencyTimer) { clearInterval(latencyTimer); latencyTimer = null; }
        if (statusTimer)  { clearInterval(statusTimer);  statusTimer = null; }
        if (mediaSource && mediaSource.readyState === 'open') {
            try { mediaSource.endOfStream(); } catch(_){}
        }
        mediaSource = null;
        sourceBuffer = null;
        audioSourceBuffer = null;
        queue = [];
        audioQueue = [];
        appending = false;
        audioAppending = false;
        hasPlayed = false;
        audioInitReceived = false;
        lastProgressCT = -1;

        if (lastInitSeg) {
            createMSE(lastInitSeg);
        }
    }

    function enqueue(data) {
        if (queue.length >= QUEUE_MAX) {
            const drop = queue.length - Math.floor(QUEUE_MAX / 2);
            queue.splice(0, drop);
            report('Dropped ' + drop + ' queued fragments');
        }
        queue.push(data);
        drainQueue();
    }

    function drainQueue() {
        if (appending || !sourceBuffer || queue.length === 0) return;
        if (sourceBuffer.updating) return;
        appending = true;
        const chunk = queue.shift();
        try {
            sourceBuffer.appendBuffer(chunk);
        } catch(e) {
            appending = false;
            report('appendBuffer error: ' + e.name);
            if (e.name === 'QuotaExceededError') {
                emergencyTrim();
            }
        }
    }

    function onUpdateEnd() {
        appending = false;
        drainQueue();

        if (!hasPlayed && sourceBuffer && sourceBuffer.buffered.length > 0) {
            attemptPlay();
        }
    }

    function attemptPlay() {
        if (hasPlayed || !sourceBuffer || sourceBuffer.buffered.length === 0) return;

        const edge = sourceBuffer.buffered.end(sourceBuffer.buffered.length - 1);
        const start = sourceBuffer.buffered.start(0);
        if (edge - start < 0.06) return;

        video.currentTime = Math.max(0, edge - 0.02);

        video.play().then(() => {
            hasPlayed = true;
            hideStatus();
            video.muted = false;
            report('PLAYING time=' + video.currentTime.toFixed(3) + ' unmuted');
        }).catch(e => {
            if (e && e.name !== 'AbortError') {
                report('play() error: ' + e.name + ' ' + (e.message || ''));
            }
        });
    }

    function startLatencyController() {
        lastProgressTime = Date.now();
        lastProgressCT = -1;

        latencyTimer = setInterval(() => {
            if (!sourceBuffer || sourceBuffer.buffered.length === 0) return;
            if (video.paused && hasPlayed) {
                video.play().catch(() => {});
            }
            if (video.paused) return;

            const now = Date.now();
            const ct  = video.currentTime;
            const edge = sourceBuffer.buffered.end(sourceBuffer.buffered.length - 1);

            const drift = edge - ct;
            if (drift > MAX_DRIFT_SEC) {
                video.currentTime = edge - 0.02;
            }

            if (Math.abs(ct - lastProgressCT) > 0.005) {
                lastProgressTime = now;
                lastProgressCT = ct;
            } else {
                const stuckFor = now - lastProgressTime;
                const hasDataAhead = (edge - ct) > 0.1;
                if (stuckFor > STALL_TIMEOUT_MS && hasDataAhead) {
                    report('Stall: ' + ct.toFixed(2) + 's for ' + (stuckFor/1000).toFixed(1) + 's — reinit');
                    lastProgressCT = -1;
                    reinitMSE();
                    return;
                }
            }

            if (now - lastTrimTime > TRIM_INTERVAL_MS && !sourceBuffer.updating) {
                const removeEnd = ct - TRIM_KEEP_BEHIND;
                const bufStart = sourceBuffer.buffered.start(0);
                if (removeEnd > bufStart + 0.1) {
                    try {
                        sourceBuffer.remove(bufStart, removeEnd);
                        lastTrimTime = now;
                    } catch(_) {}
                }
            }

            if (audioSourceBuffer && !audioSourceBuffer.updating && audioSourceBuffer.buffered.length > 0) {
                const abStart = audioSourceBuffer.buffered.start(0);
                const aRemoveEnd = ct - TRIM_KEEP_BEHIND;
                if (aRemoveEnd > abStart + 0.1) {
                    try { audioSourceBuffer.remove(abStart, aRemoveEnd); } catch(_) {}
                }
            }

            if (sourceBuffer.buffered.length > 2) {
                report('Fragmented buffer (' + sourceBuffer.buffered.length + ' ranges) — reinit');
                reinitMSE();
            }
        }, LATENCY_CHECK_MS);
    }

    function emergencyTrim() {
        if (!sourceBuffer || sourceBuffer.buffered.length === 0) return;
        try {
            const start = sourceBuffer.buffered.start(0);
            const end = Math.max(start, video.currentTime - 0.5);
            if (end > start) sourceBuffer.remove(start, end);
        } catch(_) {}
        if (audioSourceBuffer && audioSourceBuffer.buffered.length > 0) {
            try {
                const aStart = audioSourceBuffer.buffered.start(0);
                const aEnd = Math.max(aStart, video.currentTime - 0.5);
                if (aEnd > aStart) audioSourceBuffer.remove(aStart, aEnd);
            } catch(_) {}
        }
    }

    video.addEventListener('waiting', () => {
        if (!hasPlayed || !sourceBuffer || sourceBuffer.buffered.length === 0) return;
        const edge = sourceBuffer.buffered.end(sourceBuffer.buffered.length - 1);
        if (edge - video.currentTime > 0.05) {
            video.currentTime = edge - 0.02;
            report('waiting → seek to edge ' + edge.toFixed(3));
        }
    });

    video.addEventListener('stalled', () => {
        if (!sourceBuffer || sourceBuffer.buffered.length === 0) return;
        const edge = sourceBuffer.buffered.end(sourceBuffer.buffered.length - 1);
        if (edge - video.currentTime > 0.05) {
            video.currentTime = edge - 0.02;
        }
    });

    video.addEventListener('error', () => {
        const err = video.error;
        report('video error: code=' + (err ? err.code : '?'));
        if (lastInitSeg) reinitMSE();
    });

    video.addEventListener('playing', () => hideStatus());
    video.addEventListener('timeupdate', () => { if (hasPlayed) hideStatus(); });

    function detectCodec(d) {
        for (let i = 0; i < d.length - 8; i++) {
            if (d[i]===0x61 && d[i+1]===0x76 && d[i+2]===0x63 && d[i+3]===0x43) {
                if (d[i+4] === 1 && i+7 < d.length) {
                    const h = n => n.toString(16).padStart(2, '0');
                    return 'avc1.' + h(d[i+5]) + h(d[i+6]) + h(d[i+7]);
                }
            }
        }
        return null;
    }
    </script>
</body>
</html>
