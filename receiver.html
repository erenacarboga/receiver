<!DOCTYPE html>
<!--
  Custom Cast Web Receiver for Screen Mirroring
  WebSocket + fMP4 + MSE for near-real-time screen mirroring.
  v2 — segments mode, diagnostics, robust error handling.
-->
<html>
<head>
    <meta charset="utf-8">
    <script src="//www.gstatic.com/cast/sdk/libs/caf_receiver/v3/cast_receiver_framework.js"></script>
    <style>
        html, body {
            margin: 0; padding: 0;
            width: 100%; height: 100%;
            background: #000; overflow: hidden;
        }
        video { width: 100%; height: 100%; object-fit: contain; background: #000; }
        #welcome-img {
            display: none;
            position: fixed; top: 0; left: 0;
            width: 100%; height: 100%;
            object-fit: contain;
            background: #000;
            z-index: 5;
        }
        #status {
            position: fixed; top: 50%; left: 50%;
            transform: translate(-50%, -50%);
            color: #fff; font: 24px -apple-system, sans-serif;
            text-align: center; opacity: 0.8;
            transition: opacity 0.5s;
            z-index: 10;
        }
    </style>
</head>
<body>
    <div id="status">Waiting for stream...</div>
    <img id="welcome-img" />
    <video id="v" autoplay muted playsinline></video>
    <script>
    const TAG = '[SMReceiver]';
    const NS = 'urn:x-cast:com.screenmirror.stream';
    const statusEl = document.getElementById('status');
    const video = document.getElementById('v');
    const welcomeImg = document.getElementById('welcome-img');

    const ctx = cast.framework.CastReceiverContext.getInstance();
    const pm = ctx.getPlayerManager();
    let senderBusId = null;

    // Send diagnostic message back to iOS app
    function report(msg) {
        console.log(TAG, msg);
        if (senderBusId) {
            try {
                ctx.sendCustomMessage(NS, senderBusId, {type: 'DIAG', msg: msg});
            } catch(e) {}
        }
    }

    // Listen for stream commands on custom namespace
    ctx.addCustomMessageListener(NS, event => {
        senderBusId = event.senderId;
        console.log(TAG, 'Custom message from', event.senderId, ':', JSON.stringify(event.data));
        if (event.data.type === 'START_STREAM') {
            report('START_STREAM received: ' + event.data.wsUrl);
            startWebSocketStream(event.data.wsUrl);
        } else if (event.data.type === 'STOP_STREAM') {
            stopStream();
        } else if (event.data.type === 'SHOW_WELCOME') {
            report('SHOW_WELCOME: ' + event.data.imageUrl);
            showWelcome(event.data.imageUrl);
        }
    });

    // Intercept LOAD as fallback — derive WS URL from HLS URL
    pm.setMessageInterceptor(
        cast.framework.messages.MessageType.LOAD,
        loadRequest => {
            try {
                const hlsUrl = loadRequest.media.contentId;
                report('LOAD intercepted: ' + hlsUrl);
                const url = new URL(hlsUrl);
                const wsUrl = 'ws://' + url.hostname + ':8082/stream';
                startWebSocketStream(wsUrl);
            } catch (e) {
                report('LOAD intercept error: ' + e.message);
            }
            return null;
        }
    );

    const opts = new cast.framework.CastReceiverOptions();
    opts.disableIdleTimeout = true;
    opts.statusText = 'Screen Mirroring';
    opts.customNamespaces = {};
    opts.customNamespaces[NS] = cast.framework.system.MessageType.JSON;
    ctx.start(opts);
    console.log(TAG, 'Receiver v2 started');

    // ── WebSocket + MSE ──

    let ws = null, mediaSource = null, sourceBuffer = null;
    let bufferQueue = [], isAppending = false, initReceived = false;
    let hasPlayed = false, appendCount = 0, firstFragmentDTS = -1;
    let playRetryTimer = null, fatalError = false;

    function showWelcome(imageUrl) {
        stopStream();
        welcomeImg.src = imageUrl;
        welcomeImg.style.display = 'block';
        video.style.display = 'none';
        statusEl.style.opacity = '0';
    }

    function startWebSocketStream(wsUrl) {
        welcomeImg.style.display = 'none';
        video.style.display = 'block';
        report('Connecting to ' + wsUrl);
        statusEl.textContent = 'Connecting...';
        statusEl.style.opacity = '0.8';
        stopStream();

        ws = new WebSocket(wsUrl);
        ws.binaryType = 'arraybuffer';

        ws.onopen = () => {
            report('WebSocket connected');
            statusEl.textContent = 'Buffering...';
        };

        ws.onmessage = (event) => {
            const data = new Uint8Array(event.data);
            if (!initReceived) {
                initReceived = true;
                report('Init segment: ' + data.length + ' bytes');
                initMSE(data);
                return;
            }
            appendToBuffer(data);
        };

        ws.onerror = (e) => {
            report('WS error');
            statusEl.textContent = 'Connection error';
            statusEl.style.opacity = '0.8';
        };

        ws.onclose = () => {
            report('WS closed, reconnecting...');
            setTimeout(() => {
                if (ws && ws.readyState === WebSocket.CLOSED) {
                    initReceived = false;
                    startWebSocketStream(wsUrl);
                }
            }, 1000);
        };
    }

    function stopStream() {
        if (playRetryTimer) { clearInterval(playRetryTimer); playRetryTimer = null; }
        if (ws) { ws.onclose = null; ws.close(); ws = null; }
        if (mediaSource && mediaSource.readyState === 'open') {
            try { mediaSource.endOfStream(); } catch(e) {}
        }
        mediaSource = null; sourceBuffer = null;
        bufferQueue = []; isAppending = false; initReceived = false;
        hasPlayed = false; appendCount = 0; firstFragmentDTS = -1; fatalError = false;
    }

    function initMSE(initSeg) {
        mediaSource = new MediaSource();

        mediaSource.addEventListener('sourceopen', () => {
            report('MSE sourceopen');
            const codec = detectCodec(initSeg) || 'avc1.640029';
            report('Codec: ' + codec);

            try {
                sourceBuffer = mediaSource.addSourceBuffer('video/mp4; codecs="' + codec + '"');
                report('SourceBuffer created OK');
            } catch (e) {
                report('addSourceBuffer failed with ' + codec + ': ' + e.message);
                try {
                    sourceBuffer = mediaSource.addSourceBuffer('video/mp4; codecs="avc1.42E01E"');
                    report('Fallback SourceBuffer created (Baseline)');
                } catch (e2) {
                    report('Fallback addSourceBuffer also failed: ' + e2.message);
                    return;
                }
            }

            // Use segments mode (default) — timestamps from moof/tfdt are used
            sourceBuffer.addEventListener('updateend', onUpdateEnd);
            sourceBuffer.addEventListener('error', (e) => {
                report('SourceBuffer error event');
                fatalError = true;
                bufferQueue = [];
            });

            // Append init segment FIRST — must be before any fragments
            // that may have arrived via WebSocket before sourceopen fired
            bufferQueue.unshift(initSeg);
            drainQueue();

            // Start play retry timer
            playRetryTimer = setInterval(() => {
                tryPlay();
                // Report status periodically
                if (sourceBuffer && !hasPlayed) {
                    const bl = sourceBuffer.buffered.length;
                    const vp = video.paused;
                    const ct = video.currentTime.toFixed(2);
                    const re = video.readyState;
                    report('status: buffered=' + bl + ' paused=' + vp + ' time=' + ct + ' readyState=' + re + ' appends=' + appendCount + ' qLen=' + bufferQueue.length);
                }
            }, 1000);
        });

        mediaSource.addEventListener('sourceended', () => report('MSE sourceended'));
        mediaSource.addEventListener('sourceclose', () => report('MSE sourceclose'));

        video.src = URL.createObjectURL(mediaSource);
        report('video.src set, waiting for sourceopen...');
    }

    function onUpdateEnd() {
        isAppending = false;
        appendCount++;
        if (appendCount <= 3) {
            const bl = sourceBuffer.buffered.length;
            let info = 'updateend #' + appendCount + ' buffered.length=' + bl;
            if (bl > 0) {
                info += ' range=[' + sourceBuffer.buffered.start(0).toFixed(3) + ',' + sourceBuffer.buffered.end(0).toFixed(3) + ']';
            }
            report(info);
        }
        drainQueue();
        tryPlay();
    }

    function appendToBuffer(data) {
        bufferQueue.push(data);
        drainQueue();
    }

    function drainQueue() {
        if (fatalError || isAppending || !sourceBuffer || bufferQueue.length === 0) return;
        if (sourceBuffer.updating) return;
        isAppending = true;
        const chunk = bufferQueue.shift();
        try {
            sourceBuffer.appendBuffer(chunk);
        } catch (e) {
            report('appendBuffer error: ' + e.name + ' ' + e.message);
            isAppending = false;
            if (e.name === 'QuotaExceededError' && sourceBuffer.buffered.length > 0) {
                try {
                    sourceBuffer.remove(0, sourceBuffer.buffered.end(0) - 1);
                } catch(re) {}
            }
        }
    }

    function tryPlay() {
        if (!sourceBuffer) return;
        if (video.paused && sourceBuffer.buffered.length > 0) {
            const edge = sourceBuffer.buffered.end(sourceBuffer.buffered.length - 1);
            video.currentTime = Math.max(0, edge - 0.1);
            video.play().then(() => {
                if (!hasPlayed) {
                    hasPlayed = true;
                    report('PLAYING! time=' + video.currentTime.toFixed(2));
                    statusEl.style.opacity = '0';
                    if (playRetryTimer) { clearInterval(playRetryTimer); playRetryTimer = null; }
                }
            }).catch((e) => {
                report('play() rejected: ' + e.name + ' ' + e.message);
            });
        }
        // Trim old data when playing
        if (!video.paused && sourceBuffer && !sourceBuffer.updating && sourceBuffer.buffered.length > 0) {
            const trimEnd = video.currentTime - 3;
            if (trimEnd > sourceBuffer.buffered.start(0)) {
                try { sourceBuffer.remove(sourceBuffer.buffered.start(0), trimEnd); } catch(e) {}
            }
        }
    }

    // Snap to live edge if drifting
    setInterval(() => {
        if (!sourceBuffer || sourceBuffer.buffered.length === 0 || video.paused) return;
        const edge = sourceBuffer.buffered.end(sourceBuffer.buffered.length - 1);
        if (edge - video.currentTime > 1.0) {
            video.currentTime = edge - 0.05;
        }
    }, 500);

    // Video event monitoring
    video.addEventListener('error', (e) => {
        const err = video.error;
        report('video error: code=' + (err ? err.code : '?') + ' msg=' + (err ? err.message : '?'));
        fatalError = true;
        bufferQueue = [];
    });
    video.addEventListener('waiting', () => { if (hasPlayed) report('video waiting'); });
    video.addEventListener('stalled', () => report('video stalled'));

    function detectCodec(d) {
        for (let i = 0; i < d.length - 8; i++) {
            if (d[i]===0x61 && d[i+1]===0x76 && d[i+2]===0x63 && d[i+3]===0x43) {
                if (d[i+4] === 1 && i+7 < d.length) {
                    const h = n => n.toString(16).padStart(2,'0');
                    return 'avc1.' + h(d[i+5]) + h(d[i+6]) + h(d[i+7]);
                }
            }
        }
        return null;
    }
    </script>
</body>
</html>
